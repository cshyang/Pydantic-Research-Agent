{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flow\n",
    "\n",
    "Input topic -> Topic Expansion (list) \\\n",
    "Topic Expansion -> Research on relevant ropics (dict) \\\n",
    "Research on relevant topics -> Generate Outline (str) \\\n",
    "Generate Outline -> Generate Article (str) \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics Expansion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelatedTopics(BaseModel):\n",
    "    topics: List[str] = Field(description=\"A list of related topics with maximum of 3.\")\n",
    "\n",
    "\n",
    "# Create agent\n",
    "topic_explorer_agent = Agent(\n",
    "    \"openai:gpt-4o-mini\",\n",
    "    result_type=RelatedTopics,\n",
    "    system_prompt=(\n",
    "        \"You are an experienced researcher. Given a research topic, return a list of relevant topics to research on.\"\n",
    "        \"Avoid returning topics that are too broad or too specific. \"\n",
    "        \"The list of topics will then use to research on wikipedia to find relevant information. \"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "async def gen_related_topics(topic: str):\n",
    "    related_topics = await topic_explorer_agent.run(topic)\n",
    "    # related_topics_str = \", \".join(related_topics.data.topics)\n",
    "    return related_topics.data.topics\n",
    "\n",
    "\n",
    "topic = \"AI Agents in Workforce.\"\n",
    "\n",
    "related_topics = await gen_related_topics(topic)\n",
    "print(related_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research on the topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'related_topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m     35\u001b[0m tavily_search \u001b[38;5;241m=\u001b[39m TavilySearch()\n\u001b[0;32m---> 36\u001b[0m search_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m tavily_search\u001b[38;5;241m.\u001b[39mabatch_search(\u001b[43mrelated_topics\u001b[49m)\n\u001b[1;32m     37\u001b[0m search_results_str \u001b[38;5;241m=\u001b[39m TavilySearch\u001b[38;5;241m.\u001b[39mresults_to_str(search_results)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(search_results_str)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'related_topics' is not defined"
     ]
    }
   ],
   "source": [
    "from tavily import AsyncTavilyClient\n",
    "\n",
    "\n",
    "class TavilySearch:\n",
    "    def __init__(self, max_results: int = 3):\n",
    "        TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "        self.tavily_client = AsyncTavilyClient(api_key=TAVILY_API_KEY)\n",
    "        self.max_results = max_results\n",
    "\n",
    "    async def asearch(self, query: str) -> dict:\n",
    "        results = {}\n",
    "        response = await self.tavily_client.search(query, max_results=self.max_results)\n",
    "        search_results = response[\"results\"]\n",
    "        for r in search_results:\n",
    "            source = {r[\"url\"]: r[\"content\"]}\n",
    "            results.update(source)\n",
    "        return results\n",
    "\n",
    "    async def abatch_search(self, queries: list[str]) -> dict:\n",
    "        search_results = {}\n",
    "        for query in queries:\n",
    "            results = await self.asearch(query)\n",
    "            search_results.update(results)\n",
    "        return search_results\n",
    "\n",
    "    @staticmethod\n",
    "    def results_to_str(search_results: dict, max_len: int = 50_000) -> str:\n",
    "        return \"\\n\\n##########\\n\".join(\n",
    "            f\"URL:\\n {url}\\n\\nContent:\\n{content}\"\n",
    "            for url, content in search_results.items()\n",
    "        )[:max_len]\n",
    "\n",
    "\n",
    "# Usage\n",
    "tavily_search = TavilySearch()\n",
    "search_results = await tavily_search.abatch_search(related_topics)\n",
    "search_results_str = TavilySearch.results_to_str(search_results)\n",
    "\n",
    "print(search_results_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Outline\n",
    "class Subsection(BaseModel):\n",
    "    title: str = Field(description=\"The title of the subsection.\")\n",
    "    content: str = Field(description=\"The content of the subsection.\")\n",
    "\n",
    "\n",
    "class Section(BaseModel):\n",
    "    title: str = Field(description=\"The title of the section.\")\n",
    "    content: str = Field(description=\"The content of the section.\")\n",
    "    subtitles: List[Subsection] = Field(description=\"A list of subsections.\")\n",
    "\n",
    "    @property\n",
    "    def as_str(self):\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            f\"### {s.title}\\n\\n {s.content}\" for s in self.subtitles\n",
    "        )\n",
    "        return f\"## {self.title}\\n\\n{self.content}\\n\\n{subsections}\"\n",
    "\n",
    "\n",
    "class Outline(BaseModel):\n",
    "    title: str = Field(description=\"The title of the article.\")\n",
    "    sections: List[Section]\n",
    "\n",
    "    @property\n",
    "    def as_str(self):\n",
    "        sections = \"\\n\\n\".join(f\"{s.as_str}\" for s in self.sections)\n",
    "        return f\"# {self.title}\\n\\n{sections}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Article\n",
    "gen_article_agent = Agent(\n",
    "    \"openai:gpt-4o-mini\",\n",
    "    result_type=Outline,\n",
    "    deps_type=Optional[Outline],\n",
    "    system_prompt=(\n",
    "        \"You are an experienced researcher.\"\n",
    "        \"Based on the resouces gathered so far, generate an article based on the outline.\"\n",
    "        \"Use only the information provided gathered anf cite the url of the source for each section.\"\n",
    "        \"Make sure the article is informative and cohesive.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "example_article = await gen_article_agent.run(\n",
    "    search_results_str,\n",
    "    result_type=Outline,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining everything together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Tool\n",
    "\n",
    "gen_article_agent = Agent(\n",
    "    \"openai:gpt-4o-mini\",\n",
    "    result_type=Outline,\n",
    "    deps_type=Optional[Outline],\n",
    "    system_prompt=(\n",
    "        \"You are an experienced researcher, given a research topic, use gen_related_topics to find more relevant topics.\"\n",
    "        \"Use tavily_search.abatch_search tool to gather relevant information with the relevant topics.\"\n",
    "        \"Based on the resouces gathered, generate an article based on the outline.\"\n",
    "        \"Use only the information provided gathered anf cite the url of the source for each section.\"\n",
    "        \"Make sure the article is informative and cohesive.\"\n",
    "    ),\n",
    "    tools=[Tool(tavily_search.abatch_search), Tool(gen_related_topics)],\n",
    ")\n",
    "\n",
    "article = await gen_article_agent.run(\"local AI adoption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(article.data.as_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "Based on the research results, update the initial outline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(example_article.data.as_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.all_messages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
